

<!DOCTYPE html>
<html lang="en" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/moca.png">
  <link rel="icon" href="/img/moca.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="John Doe">
  <meta name="keywords" content="">
  
    <meta name="description" content="Spam ClassificationThis is the final assignment of undergraduate elective course of UCAS: Data Mining, which may be helpful to you. Problem Descriptionproblem link: https:&#x2F;&#x2F;challenge.datacastle.cn&#x2F;v3&#x2F;">
<meta property="og:type" content="article">
<meta property="og:title" content="Spam classification using classic models">
<meta property="og:url" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/index.html">
<meta property="og:site_name" content="YJK&#39;s blog">
<meta property="og:description" content="Spam ClassificationThis is the final assignment of undergraduate elective course of UCAS: Data Mining, which may be helpful to you. Problem Descriptionproblem link: https:&#x2F;&#x2F;challenge.datacastle.cn&#x2F;v3&#x2F;">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-7.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-8.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-18.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-9.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-1.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-10.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-3.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-11.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-2.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-14.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-15.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-16.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-17.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-19.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-20.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-21.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-23.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-12.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-13.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-24.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-4.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-25.png">
<meta property="og:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-26.png">
<meta property="article:published_time" content="2024-07-26T08:40:36.000Z">
<meta property="article:modified_time" content="2024-07-26T09:59:00.127Z">
<meta property="article:author" content="John Doe">
<meta property="article:tag" content="machine learning">
<meta property="article:tag" content="data mining">
<meta property="article:tag" content="bayes classifier">
<meta property="article:tag" content="logistic regression">
<meta property="article:tag" content="SVM">
<meta property="article:tag" content="decision tree">
<meta property="article:tag" content="random forest">
<meta property="article:tag" content="MLP">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://example.com/2024/07/26/Spam-classification-using-classic-models/image/image-7.png">
  
  
  
  <title>Spam classification using classic models - YJK&#39;s blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"example.com","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/xiaobai.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":true,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":"88dRqUgSKZbis5Ll3Z2I7ksP-gzGzoHsz","app_key":"5DeS0vBGMOo5VMq9USNgpK5E","server_url":"https://88drqugs.lc-cn-n1-shared.com","path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  

  

  
    <!-- Google tag (gtag.js) -->
    <script async>
      if (!Fluid.ctx.dnt) {
        Fluid.utils.createScript("https://www.googletagmanager.com/gtag/js?id=", function() {
          window.dataLayer = window.dataLayer || [];
          function gtag() {
            dataLayer.push(arguments);
          }
          gtag('js', new Date());
          gtag('config', '');
        });
      }
    </script>
  

  

  

  

  
    
  



  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>YJK&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/default.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.3)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="Spam classification using classic models"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-07-26 16:40" pubdate>
          July 26, 2024 pm
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          1.1k words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          10 mins
        
      </span>
    

    
    
      
        <span id="leancloud-page-views-container" class="post-meta" style="display: none">
          <i class="iconfont icon-eye" aria-hidden="true"></i>
          <span id="leancloud-page-views"></span> times
        </span>
        
      
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

<script>
  function getRandomNumber(min, max) {
    min = Math.ceil(min);
    max = Math.floor(max);
    return Math.floor(Math.random() * (max - min + 1)) + min;
  }


var randomNum = getRandomNumber(0, 8).toString();
var banner_img = "/img/random-bg/" + randomNum + ".avif";
document.getElementById('banner').removeAttribute('style')
document.getElementById('banner').setAttribute('style',`background: url('${banner_img}') no-repeat center center; background-size: cover;`)
</script>
</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

<iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width=265 height=300 src="//music.163.com/outchain/player?type=0&id=12351705900&auto=1&height=430"></iframe>
    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">Spam classification using classic models</h1>
            
            
              <div class="markdown-body">
                
                <h2 id="Spam-Classification"><a href="#Spam-Classification" class="headerlink" title="Spam Classification"></a>Spam Classification</h2><p>This is the final assignment of undergraduate elective course of UCAS: <em>Data Mining</em>, which may be helpful to you.</p>
<h3 id="Problem-Description"><a href="#Problem-Description" class="headerlink" title="Problem Description"></a>Problem Description</h3><p>problem link: <a target="_blank" rel="noopener" href="https://challenge.datacastle.cn/v3/cmptDetail.html?id=352">https://challenge.datacastle.cn/v3/cmptDetail.html?id=352</a></p>
<p>Given email text information, establish a classification model to determine which emails are spam.</p>
<h3 id="Phone-Number-Checker"><a href="#Phone-Number-Checker" class="headerlink" title="Phone Number Checker"></a>Phone Number Checker</h3><h4 id="1-Theory"><a href="#1-Theory" class="headerlink" title="1.Theory"></a>1.Theory</h4><p>After downloading the training and testing data, I observed the spam text in the training set, trying to find some obvious features. I found that the vast majority of spam emails would contain “phone numbers”, usually a string of 11 in length, sometimes connected by characters such as spaces or ‘-‘ in the middle of the numbers.</p>
<p><img src="image/image-7.png" srcset="/img/xiaobai.gif" lazyload alt=""><br><img src="image/image-8.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>So a natural idea is to mark all emails with phone numbers as spam, otherwise they are considered normal emails. Method for identifying phone numbers: Use a sliding window to check all consecutive 13 digit strings in the text. If 9 or more digits are digits, it is considered a phone number. For example, “0871-872-9755” will be recognized as a phone number.</p>
<h4 id="2-Code"><a href="#2-Code" class="headerlink" title="2.Code"></a>2.Code</h4><p>Critical Code:</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">def</span> <span class="hljs-title function_">check_phone_number</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-comment"># Count the number of digits in the string</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">count_digits</span>(<span class="hljs-params">s</span>):<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">sum</span>(c.isdigit() <span class="hljs-keyword">for</span> c <span class="hljs-keyword">in</span> s)<br><br>    <span class="hljs-comment"># Check every window of length 13 in the text</span><br>    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-number">0</span>, <span class="hljs-built_in">len</span>(text) - <span class="hljs-number">12</span>):<br>        <span class="hljs-keyword">if</span>(count_digits(text[i:i+<span class="hljs-number">13</span>]) &gt;= <span class="hljs-number">9</span>):<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br><span class="hljs-comment"># 构建输出</span><br><span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> test_data_df.iterrows():<br>    <span class="hljs-built_in">id</span> = row[<span class="hljs-string">&#x27;ID&#x27;</span>]<br>    <span class="hljs-keyword">if</span> check_phone_number(row[<span class="hljs-string">&#x27;Email&#x27;</span>]):    <span class="hljs-comment"># If a phone number is recognized in the text</span><br>        Label = <span class="hljs-string">&#x27;spam&#x27;</span>  <span class="hljs-comment"># Mark as spam</span><br>    <span class="hljs-keyword">else</span>:<br>        Label = <span class="hljs-string">&#x27;ham&#x27;</span><br>    new_row = pd.DataFrame([[<span class="hljs-built_in">id</span>, Label]], columns = [<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;Label&#x27;</span>])<br>    result_df = pd.concat([result_df, new_row], ignore_index = <span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<h4 id="3-Result"><a href="#3-Result" class="headerlink" title="3.Result"></a>3.Result</h4><p><img src="image/image-18.png" srcset="/img/xiaobai.gif" lazyload alt=""><br><img src="image/image.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>The accuracy on the training set is about 0.9457, and the accuracy on the test set is about 0.9434.</p>
<p>The initial way to identify phone numbers was to have 11 or more digits in a 13 length sliding window, with an accuracy rate of 0.9372.</p>
<p>It was discovered that some numbers were less than 11 digits and should still be recognized as phone numbers. The method of identifying phone numbers was changed to a 13 length sliding window with 9 or more digits. The accuracy of the test set was improved to 0.9434.</p>
<h3 id="Naive-Bayes-regression-model-based-on-bag-of-words"><a href="#Naive-Bayes-regression-model-based-on-bag-of-words" class="headerlink" title="Naive Bayes regression model based on bag of words"></a>Naive Bayes regression model based on bag of words</h3><h4 id="1-Theory-1"><a href="#1-Theory-1" class="headerlink" title="1.Theory"></a>1.Theory</h4><p>Build a big word bag for all spam emails and a big word bag for all normal emails.</p>
<p>First, calculate the prior probability: take the proportion of spam and normal emails in the training set samples as the prior probability.</p>
<p>Then multiply the frequency of each word appearing in spam emails to obtain the probability that the email is spam, and multiply the probability of each word appearing in normal emails to obtain the probability that the email is normal. Compare the two probabilities and take the larger one as the prediction result.</p>
<p>Laplace smoothing was used to avoid the problem of calculating a probability of 0 when the frequency of a word in the bag of words is 0.</p>
<h4 id="2-Code-1"><a href="#2-Code-1" class="headerlink" title="2.Code"></a>2.Code</h4><p>Critical Code:</p>
<p>(1) Data Processing：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">def</span> <span class="hljs-title function_">remove_punctuation</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-comment"># Use regular expressions to match any character that is not a letter, number, or space and replace it with a space</span><br>    text = re.sub(<span class="hljs-string">r&#x27;[^\w\s]&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>, text)<br>    <span class="hljs-keyword">return</span> text<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">change_digit_to_zero</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-comment"># Match all numbers using regular expressions and replace them with the string &#x27;0&#x27;</span><br>    <span class="hljs-keyword">return</span> re.sub(<span class="hljs-string">r&#x27;\d&#x27;</span>, <span class="hljs-string">&#x27;0&#x27;</span>, text)<br><br><span class="hljs-comment"># Process the text, remove punctuation and convert all to lowercase</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_text</span>(<span class="hljs-params">text</span>):<br>    text = remove_punctuation(text)<br>    text = change_digit_to_zero(text)<br>    text = text.lower()<br>    <span class="hljs-keyword">return</span> text<br><br><span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> train_data_df.iterrows():<br>    text = init_text(row[<span class="hljs-string">&#x27;Email&#x27;</span>])<br>    <span class="hljs-comment"># Put the processed text into different lists according to labels</span><br>    <span class="hljs-keyword">if</span>(row[<span class="hljs-string">&#x27;Label&#x27;</span>] == <span class="hljs-string">&#x27;spam&#x27;</span>):<br>        spam_emails.append(text)<br>    <span class="hljs-keyword">else</span>:<br>        ham_emails.append(text)<br><br><span class="hljs-comment"># Count the frequency of each word appearing in spam and normal files</span><br><span class="hljs-keyword">for</span> email <span class="hljs-keyword">in</span> spam_emails:<br>    words = email.split()   <span class="hljs-comment"># Split by one or more spaces</span><br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> words:      <span class="hljs-comment"># Build a word bag</span><br>        spam_word_count[word] = spam_word_count.get(word, <span class="hljs-number">0</span>) + <span class="hljs-number">1</span><br><br><span class="hljs-keyword">for</span> email <span class="hljs-keyword">in</span> ham_emails:<br>    words = email.split()<br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> words:<br>        ham_word_count[word] = ham_word_count.get(word, <span class="hljs-number">0</span>) + <span class="hljs-number">1</span><br><br><span class="hljs-comment"># Calculate prior probability</span><br>spam_prior_prob = <span class="hljs-built_in">len</span>(spam_emails) / (<span class="hljs-built_in">len</span>(spam_emails) + <span class="hljs-built_in">len</span>(ham_emails))<br>ham_prior_prob  = <span class="hljs-built_in">len</span>(ham_emails)  / (<span class="hljs-built_in">len</span>(spam_emails) + <span class="hljs-built_in">len</span>(ham_emails))<br><br></code></pre></td></tr></table></figure>
<p>(2) Prediction:<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs py"><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">email</span>): <span class="hljs-comment"># Predicting whether it is spam based on email text</span><br>    text = init_text(email) <span class="hljs-comment"># Initialize text</span><br>    word_count = &#123;&#125;<br>    words = text.split()    <span class="hljs-comment"># Split by one or more spaces</span><br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> words:      <span class="hljs-comment"># Build a word bag</span><br>        word_count[word] = word_count.get(word, <span class="hljs-number">0</span>) + <span class="hljs-number">1</span><br>    <br>    spam_prob = spam_prior_prob<br>    ham_prob = ham_prior_prob<br>    <br>    <span class="hljs-keyword">for</span> word, count <span class="hljs-keyword">in</span> word_count.items():<br>        <span class="hljs-comment"># Laplace smoothing</span><br>        spam_prob *= (spam_word_count.get(word, <span class="hljs-number">0</span>) + <span class="hljs-number">1</span>) / (<span class="hljs-built_in">sum</span>(spam_word_count.values()) + <span class="hljs-built_in">len</span>(word_count))<br>        ham_prob *= (ham_word_count.get(word, <span class="hljs-number">0</span>) + <span class="hljs-number">1</span>) / (<span class="hljs-built_in">sum</span>(ham_word_count.values()) + <span class="hljs-built_in">len</span>(word_count))<br>        <span class="hljs-keyword">if</span>((spam_prob &lt; <span class="hljs-number">1e-6</span>) | (ham_prob &lt; <span class="hljs-number">1e-6</span>)):<br>            spam_prob *= <span class="hljs-number">1e6</span><br>            ham_prob *= <span class="hljs-number">1e6</span><br>    <br>    <span class="hljs-keyword">if</span>(spam_prob &gt; ham_prob):<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;spam&#x27;</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-string">&#x27;ham&#x27;</span><br></code></pre></td></tr></table></figure></p>
<h4 id="3-Result-1"><a href="#3-Result-1" class="headerlink" title="3.Result"></a>3.Result</h4><p><img src="image/image-9.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>(1) Training time</p>
<p>The total time of training and prediction is 6.44s</p>
<p>(2) Accuracy on the training set</p>
<p>Accuracy on the training set is 0.9850</p>
<p>(3) Accuracy on the test set</p>
<p><img src="image/image-1.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>The accuracy is 0.9452 without processing the numerical string.</p>
<p>Considering that phone numbers are a string of numbers, each spam phone call is different, but essentially can be seen as the same word. In order to make them play their due role, I converted all numbers to the number 0, and the accuracy was improved to 0.947.</p>
<p>At first, when dividing words, I directly deleted punctuation marks:</p>
<blockquote>
<p>text = re.sub(r’<sup><a href="#fn_\w\s" id="reffn_\w\s">\w\s</a></sup>‘, ‘’, text)</p>
</blockquote>
<p>Later, it was discovered that some words separated by symbols did not have spaces in between, such as ‘… ‘, After removing punctuation marks, the two words became connected, so I changed the data processing method to replace punctuation marks with spaces:</p>
<blockquote>
<p>text = re.sub(r’<sup><a href="#fn_\w\s" id="reffn_\w\s">\w\s</a></sup>‘, ‘ ‘, text)</p>
</blockquote>
<p>The accuracy has been improved to 0.9587.</p>
<h3 id="Naive-Bayes-Model-Based-on-TF-IDF"><a href="#Naive-Bayes-Model-Based-on-TF-IDF" class="headerlink" title="Naive Bayes Model Based on TF-IDF"></a>Naive Bayes Model Based on TF-IDF</h3><h4 id="1-Theory-2"><a href="#1-Theory-2" class="headerlink" title="1.Theory"></a>1.Theory</h4><p>Email text initialization:</p>
<ol>
<li>Replace punctuation with spaces</li>
<li>Replace all numbers with ‘0’</li>
<li>Convert all letters to lowercase</li>
<li>Divide each word into one or more spaces</li>
<li>Merge the segmentation results into a string with only one space between each word</li>
</ol>
<p>Call <em>CountVectorizer()</em> to segment each email into $n$ small word bags. Assuming all texts have m different words, each sample have $m$ features, representing the number of times each word appears in the email.</p>
<p>Call <em>TfidfTransformer()</em> to calculate the TF-IDF value of each small bag of words. At this point, the $m$ features of each sample become the corresponding TF-IDF values of $m$ words in the email text.</p>
<p>At this point, only a <em>Multidimensional Feature Classification</em> problem needs to be solved, which can be predicted through various methods such as naive Bayes model, logistic regression, support vector machine, etc.</p>
<h4 id="2-Code-2"><a href="#2-Code-2" class="headerlink" title="2.Code"></a>2.Code</h4><p>Critical Code:</p>
<p>(1) Data Processing：<em>CountVectorizer()</em> was called to construct the bag of words, and <em>TfidfTransformer()</em> was called to calculate the TF-IDF value.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">def</span> <span class="hljs-title function_">remove_punctuation</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-comment"># Use regular expressions to match any character that is not a letter, number, or space and replace it with a space</span><br>    text = re.sub(<span class="hljs-string">r&#x27;[^\w\s]&#x27;</span>, <span class="hljs-string">&#x27; &#x27;</span>, text)<br>    <span class="hljs-keyword">return</span> text<br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">change_digit_to_zero</span>(<span class="hljs-params">text</span>):<br>    <span class="hljs-comment"># Match all numbers using regular expressions and replace them with the string &#x27;0&#x27;</span><br>    <span class="hljs-keyword">return</span> re.sub(<span class="hljs-string">r&#x27;\d&#x27;</span>, <span class="hljs-string">&#x27;0&#x27;</span>, text)<br><br><span class="hljs-comment"># Initialize the text</span><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">init_text</span>(<span class="hljs-params">text</span>):<br>    text = remove_punctuation(text)<br>    text = change_digit_to_zero(text)<br>    text = text.lower()<br>    words = text.split()<br>    <span class="hljs-comment"># Merge the segmentation results into a string with only one space between each word</span><br>    text = <span class="hljs-string">&quot; &quot;</span>.join(words)<br>    <span class="hljs-keyword">return</span> text<br><br>train_text_list = []<br>test_text_list = []<br><br><span class="hljs-comment"># Initialize the text and save it to a list</span><br><span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> train_data_df.iterrows():<br>    text = init_text(row[<span class="hljs-string">&#x27;Email&#x27;</span>])<br>    train_text_list.append(text)<br><br><span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> test_data_df.iterrows():<br>    text = init_text(row[<span class="hljs-string">&#x27;Email&#x27;</span>])<br>    test_text_list.append(text)<br><br><span class="hljs-comment"># Create a bag of words data structure</span><br>cv = CountVectorizer(max_features = <span class="hljs-number">3000</span>, max_df = <span class="hljs-number">0.1</span>, min_df = <span class="hljs-number">7</span>) <br>count = cv.fit_transform(train_text_list + test_text_list)<br>train_count = count[<span class="hljs-number">0</span> : <span class="hljs-built_in">len</span>(train_text_list)]<br>test_count = count[<span class="hljs-built_in">len</span>(train_text_list) : <span class="hljs-built_in">len</span>(train_text_list) + <span class="hljs-built_in">len</span>(test_text_list)]<br><br><span class="hljs-comment"># Calculate TF-IDF</span><br>tfidf = TfidfTransformer()<br>train_tfidf_matrix = tfidf.fit_transform(train_count)<br>test_tfidf_matrix = tfidf.fit_transform(test_count)<br></code></pre></td></tr></table></figure>
<p>(2) Model training: MultinomialNB() was called to implement a Naive Bayes model with a prior of polynomial distribution.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment"># Train Bayes model on the training set</span><br>bayes_model = MultinomialNB()<br>bayes_model.fit(train_tfidf_matrix, train_data_df[<span class="hljs-string">&#x27;Label&#x27;</span>].tolist())<br> <br><span class="hljs-comment"># Get the score on training set</span><br>score = bayes_model.score(train_tfidf_matrix, train_data_df[<span class="hljs-string">&#x27;Label&#x27;</span>].tolist())<br><span class="hljs-built_in">print</span>(score)<br><br><span class="hljs-comment"># Get the prediction result</span><br>y_pred = bayes_model.predict(test_tfidf_matrix)<br></code></pre></td></tr></table></figure>
<h4 id="3-Result-2"><a href="#3-Result-2" class="headerlink" title="3.Result"></a>3.Result</h4><p><img src="image/image-10.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>(1) Training time</p>
<p>The total training and prediction time is 0.27s</p>
<p>(2) Accuracy on the training set</p>
<p>The accuracy of prediction on the training set is 0.9901.</p>
<p>(3) Accuracy on the test set</p>
<p><img src="image/image-3.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>The accuracy of prediction on the test set is 0.9847.</p>
<h3 id="Logistic-regression"><a href="#Logistic-regression" class="headerlink" title="Logistic regression"></a>Logistic regression</h3><h4 id="1-Theory-3"><a href="#1-Theory-3" class="headerlink" title="1.Theory"></a>1.Theory</h4><p>By constructing TF-IDF as input features in the manner described above, it can be transformed into a classification problem with multidimensional features, and a logistic regression model can be used for prediction.</p>
<h4 id="2-Code-3"><a href="#2-Code-3" class="headerlink" title="2.Code"></a>2.Code</h4><p>Critical Code:</p>
<p>(1) Data Processing：Data Processing consistent with the naive Bayes model based on TF-IDF</p>
<p>(2) Model training: <em>LogisticRegressionCV</em> was called to implement the logistic regression model</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment"># Train logistic regression models on the training set</span><br>lr_model = LogisticRegressionCV(max_iter = <span class="hljs-number">100000</span>)<br>lr_model.fit(train_tfidf_matrix, train_data_df[<span class="hljs-string">&#x27;Label&#x27;</span>].tolist())<br> <br><span class="hljs-comment"># Get the score on training set</span><br>score = lr_model.score(train_tfidf_matrix, train_data_df[<span class="hljs-string">&#x27;Label&#x27;</span>].tolist())<br><span class="hljs-built_in">print</span>(score)<br><br><span class="hljs-comment"># Get the prediction result</span><br>y_pred = lr_model.predict(test_tfidf_matrix)<br></code></pre></td></tr></table></figure>
<h4 id="3-Result-3"><a href="#3-Result-3" class="headerlink" title="3.Result"></a>3.Result</h4><p><img src="image/image-11.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>(1) Training time</p>
<p>The total training and prediction time is 1.63s</p>
<p>(2) Accuracy on the training set</p>
<p>The accuracy of prediction on the training set is 1.0</p>
<p>(3) Accuracy on the test set</p>
<p><img src="image/image-2.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>The accuracy of prediction on the test set is 0.9865</p>
<h3 id="SVM"><a href="#SVM" class="headerlink" title="SVM"></a>SVM</h3><h4 id="1-Theory-4"><a href="#1-Theory-4" class="headerlink" title="1.Theory"></a>1.Theory</h4><p>By constructing TF-IDF as input features in the manner described above, it can be transformed into a classification problem with multidimensional features, and a SVM model can be used for prediction.</p>
<h4 id="2-Code-4"><a href="#2-Code-4" class="headerlink" title="2.Code"></a>2.Code</h4><p>critical code：</p>
<p>(1) Data Processing: It is basically the same as the Bayesian model and logistic regression model based on TF-IDF, with the only difference being the need to convert ‘ham’ and ‘spam’ into 0 and 1.</p>
<p>(2) The training process only changed the called model, and the other steps are basically the same.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment"># Convert the strings &#x27;ham&#x27; and &#x27;spam&#x27; of Label to 0 and 1, respectively</span><br>train_y = []<br><span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> train_data_df.iterrows():<br>    label_bool = (row[<span class="hljs-string">&#x27;Label&#x27;</span>] == <span class="hljs-string">&#x27;spam&#x27;</span>)<br>    train_y.append(<span class="hljs-number">0.0</span> + label_bool)<br><br><span class="hljs-comment"># Train support vector machine models on the training set</span><br>SVR_model = LinearSVC()<br>SVR_model.fit(train_tfidf_matrix, train_y)<br><br><span class="hljs-comment"># Get the prediction result</span><br>y_pred = SVR_model.predict(test_tfidf_matrix)<br></code></pre></td></tr></table></figure>
<h4 id="3-Result-4"><a href="#3-Result-4" class="headerlink" title="3.Result"></a>3.Result</h4><p><img src="image/image-14.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>(1) Training time</p>
<p>The total training and prediction time is 0.35s</p>
<p>(2) Accuracy on the training set</p>
<p>The accuracy of prediction on the training set is 0.9978</p>
<p>(3) Accuracy on the test set</p>
<p><img src="image/image-15.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>The accuracy of prediction on the test set is 0.9874</p>
<h3 id="Other-classification-models-Decision-Tree-Random-Forest-Multilayer-Perceptron"><a href="#Other-classification-models-Decision-Tree-Random-Forest-Multilayer-Perceptron" class="headerlink" title="Other classification models (Decision Tree, Random Forest, Multilayer Perceptron)"></a>Other classification models (Decision Tree, Random Forest, Multilayer Perceptron)</h3><h4 id="1-Theory-5"><a href="#1-Theory-5" class="headerlink" title="1.Theory"></a>1.Theory</h4><p>Due to their data processing methods being roughly consistent with the Bayes, Logistic Regression, and SVM based on TF-IDF mentioned above, all of which are packet switching solutions for a multidimensional feature classification problem, they will not be further elaborated。</p>
<h4 id="2-Code-5"><a href="#2-Code-5" class="headerlink" title="2.Code"></a>2.Code</h4><p>Decision Tree：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment"># Train a SVM model on the training set</span><br>DTR_model = DecisionTreeRegressor()<br>DTR_model.fit(train_tfidf_matrix, train_y)<br><br><span class="hljs-comment"># Get the prediction result</span><br>y_pred = DTR_model.predict(test_tfidf_matrix)<br></code></pre></td></tr></table></figure>
<p>Random Forest：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment"># Train a Random Forest model on the training set</span><br>RF_model = RandomForestClassifier()<br>RF_model.fit(train_tfidf_matrix, train_y)<br><br><span class="hljs-comment"># Get the prediction result</span><br>y_pred = RF_model.predict(test_tfidf_matrix)<br></code></pre></td></tr></table></figure>
<p>Multilayer Perceptron：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment"># Train a MLP model on the training set</span><br>MLP_model = MLPRegressor()<br>MLP_model.fit(train_tfidf_matrix, train_y)<br><br><span class="hljs-comment"># Get the prediction result</span><br>y_pred = MLP_model.predict(test_tfidf_matrix)<br></code></pre></td></tr></table></figure>
<h4 id="3-Result-5"><a href="#3-Result-5" class="headerlink" title="3.Result"></a>3.Result</h4><p>Decision Tree:</p>
<p><img src="image/image-16.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p><img src="image/image-17.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>Training time is 0.72s.</p>
<p>The accuracy of prediction on the training set is 0.9981.</p>
<p>Accuracy on the test set is 0.9390.</p>
<p>Random Forest：</p>
<p><img src="image/image-19.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p><img src="image/image-20.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>Training time is 3.37s.</p>
<p>The accuracy of prediction on the training set is 0.9997.</p>
<p>The accuracy of prediction on the test set is 0.9874.</p>
<p>Multilayer Perceptron：</p>
<p><img src="image/image-21.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p><img src="image/image-23.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>Training time is 8.51s.</p>
<p>The accuracy of prediction on the training set is 0.9968.</p>
<p>The accuracy of prediction on the test set is 0.9919.</p>
<h3 id="Combination-Model"><a href="#Combination-Model" class="headerlink" title="Combination Model"></a>Combination Model</h3><h4 id="1-Theory-6"><a href="#1-Theory-6" class="headerlink" title="1.Theory"></a>1.Theory</h4><p>I have implemented a Bayesian model and a Logistic Regression model based on TF-IDF, and their prediction accuracy is not much different. </p>
<p>Considering how to combine them, a natural idea is to let the two models make separate predictions. If the prediction results of the two models are the same, it is considered as the prediction result. Otherwise, we will use other methods to determine whether it is spam.</p>
<p>I printed out all the email texts with different prediction results from two models：</p>
<p><img src="image/image-12.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>I found that most of these samples are spam emails. I guess both models have a tendency to predict some spam emails as normal emails, so a simple judgment method was adopted: all emails with different prediction results from the two models were treated as spam emails.</p>
<p>I also tried using Bayesian model, logistic regression model, and support vector machine model to predict simultaneously, and then selected the most frequently occurring classification from the three results as the final classification, but the performance did not improve on the test set. But if samples with different results among them are treated as spam emails, their scores on the test set will be improved.</p>
<p>Afterwards, I tried using five models including Bayesian, logistic regression, SVM, random forest, and MLP for simultaneous prediction. The prediction results of the five models were voted to obtain the final result, but there was no improvement in accuracy on the test set. Considering that the model has a tendency to predict some spam emails as normal emails, I attempted to take spam as the final result if any of the five models predicted it as spam. The accuracy of the results on the test set was improved.</p>
<h4 id="2-Code-6"><a href="#2-Code-6" class="headerlink" title="2.Code"></a>2.Code</h4><p>critical code：</p>
<p>(1) Bayes and logistic regression combination model：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment"># Train logistic regression models on the training set</span><br>lr_model = LogisticRegressionCV(max_iter = <span class="hljs-number">100000</span>)<br>lr_model.fit(train_tfidf_matrix, train_data_df[<span class="hljs-string">&#x27;Label&#x27;</span>].tolist())<br><br><span class="hljs-comment"># Train Bayes models on the training set</span><br>bayes_model = MultinomialNB()<br>bayes_model.fit(train_tfidf_matrix, train_data_df[<span class="hljs-string">&#x27;Label&#x27;</span>].tolist())<br><br><span class="hljs-comment"># Get the prediction result</span><br>y_logistic_pred = lr_model.predict(test_tfidf_matrix)<br>y_bayes_pred = bayes_model.predict(test_tfidf_matrix)<br><br><span class="hljs-comment"># Get the result</span><br><span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> test_data_df.iterrows():<br>    <span class="hljs-built_in">id</span> = row[<span class="hljs-string">&#x27;ID&#x27;</span>]<br>    label1 = y_logistic_pred[index]<br>    label2 = y_bayes_pred[index]<br>    <span class="hljs-keyword">if</span>(label1 == label2): <span class="hljs-comment"># Compare the prediction result of two models</span><br>        label = label1  <span class="hljs-comment"># If they are the same, use it as the prediction result</span><br>    <span class="hljs-keyword">else</span>:   <span class="hljs-comment"># mark it as spam</span><br>        <span class="hljs-built_in">print</span>(row[<span class="hljs-string">&#x27;Email&#x27;</span>])<br>        label = <span class="hljs-string">&#x27;spam&#x27;</span><br>    new_row = pd.DataFrame([[<span class="hljs-built_in">id</span>, label]], columns = [<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;Label&#x27;</span>])<br>    result_df = pd.concat([result_df, new_row], ignore_index = <span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<p>(2) Five models combination：</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br></pre></td><td class="code"><pre><code class="hljs py">SVR_model = LinearSVC()<br>SVR_model.fit(train_tfidf_matrix, train_y)<br> <br>lr_model = LogisticRegressionCV(max_iter = <span class="hljs-number">100000</span>)<br>lr_model.fit(train_tfidf_matrix, train_y)<br><br>bayes_model = MultinomialNB()<br>bayes_model.fit(train_tfidf_matrix, train_y)<br><br>MLP_model = MLPRegressor()<br>MLP_model.fit(train_tfidf_matrix, train_y)<br><br>RF_model = RandomForestClassifier()<br>RF_model.fit(train_tfidf_matrix, train_y)<br><br>y_logistic_pred = lr_model.predict(test_tfidf_matrix)<br>y_bayes_pred = bayes_model.predict(test_tfidf_matrix)<br>y_SVR_pred = SVR_model.predict(test_tfidf_matrix)<br>y_RF_pred = RF_model.predict(test_tfidf_matrix)<br>y_MLP_pred = MLP_model.predict(test_tfidf_matrix)<br><br>y_logistic_train = lr_model.predict(train_tfidf_matrix)<br>y_bayes_train = bayes_model.predict(train_tfidf_matrix)<br>y_SVR_train = SVR_model.predict(train_tfidf_matrix)<br>y_RF_train = RF_model.predict(train_tfidf_matrix)<br>y_MLP_train = MLP_model.predict(train_tfidf_matrix)<br><br>right_cnt = <span class="hljs-number">0</span><br>wrong_cnt = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> train_data_df.iterrows():<br>    <span class="hljs-keyword">if</span> y_MLP_train[index] &gt; <span class="hljs-number">0.5</span>:<br>        y_MLP = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        y_MLP = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">if</span>(y_logistic_train[index] + y_bayes_train[index] + y_SVR_train[index] + y_RF_train[index] + y_MLP &gt;= <span class="hljs-number">1.0</span>):<br>        label = <span class="hljs-string">&#x27;spam&#x27;</span><br>    <span class="hljs-keyword">else</span>:<br>        label = <span class="hljs-string">&#x27;ham&#x27;</span><br>    <span class="hljs-keyword">if</span>(label == row[<span class="hljs-string">&#x27;Label&#x27;</span>]):<br>        right_cnt += <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        wrong_cnt += <span class="hljs-number">1</span><br><span class="hljs-built_in">print</span>(right_cnt / (right_cnt + wrong_cnt))<br><br><span class="hljs-keyword">for</span> index, row <span class="hljs-keyword">in</span> test_data_df.iterrows():<br>    <span class="hljs-keyword">if</span> y_MLP_pred[index] &gt; <span class="hljs-number">0.5</span>:<br>        y_MLP = <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        y_MLP = <span class="hljs-number">0</span><br>    <span class="hljs-keyword">if</span>(y_logistic_pred[index] + y_bayes_pred[index] + y_SVR_pred[index] + y_RF_pred[index] + y_MLP &gt;= <span class="hljs-number">1.0</span>):<br>        label = <span class="hljs-string">&#x27;spam&#x27;</span><br>    <span class="hljs-keyword">else</span>:<br>        label = <span class="hljs-string">&#x27;ham&#x27;</span><br>    <span class="hljs-built_in">id</span> = row[<span class="hljs-string">&#x27;ID&#x27;</span>]<br>    new_row = pd.DataFrame([[<span class="hljs-built_in">id</span>, label]], columns = [<span class="hljs-string">&#x27;ID&#x27;</span>, <span class="hljs-string">&#x27;Label&#x27;</span>])<br>    result_df = pd.concat([result_df, new_row], ignore_index = <span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>
<h4 id="3-Result-6"><a href="#3-Result-6" class="headerlink" title="3.Result"></a>3.Result</h4><p><img src="image/image-13.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p><img src="image/image-24.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>(1) Training time</p>
<p>Combination of two models: The total training and prediction time is 1.91s.<br>Combination of five models: The total training and prediction time is 12.20s.</p>
<p>(2) Accuracy on the training set</p>
<p>Combination of two models: The accuracy of prediction on the training set is 1.0.<br>Combination of five models: The accuracy of prediction on the training set is 0.9991.</p>
<p>(3) Accuracy on the test set</p>
<p><img src="image/image-4.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p><img src="image/image-25.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>Combination of two models: The accuracy of prediction on the test set is 0.9883.<br>Combination of five models: The accuracy of prediction on the test set is 0.9919.</p>
<h3 id="Result-and-Summary"><a href="#Result-and-Summary" class="headerlink" title="Result and Summary"></a>Result and Summary</h3><h4 id="Ranking"><a href="#Ranking" class="headerlink" title="Ranking"></a>Ranking</h4><p><img src="image/image-26.png" srcset="/img/xiaobai.gif" lazyload alt=""></p>
<p>As shown above, among all the prediction results I submitted, the highest accuracy on the test set was 0.9919, ranking 11th</p>
<h4 id="Comparison-of-different-models"><a href="#Comparison-of-different-models" class="headerlink" title="Comparison of different models"></a>Comparison of different models</h4><div class="table-container">
<table>
<thead>
<tr>
<th>Model</th>
<th>Training time</th>
<th>Accuracy on the training set</th>
<th>Accuracy on the test set</th>
</tr>
</thead>
<tbody>
<tr>
<td>Phone Number Checker</td>
<td>-</td>
<td>0.9457</td>
<td>0.9434</td>
</tr>
<tr>
<td>Bayes Classifier based on Bag of Words</td>
<td>6.44s</td>
<td>0.9850</td>
<td>0.9587</td>
</tr>
<tr>
<td>Bayes Classifier based on TF-IDF</td>
<td>0.27s</td>
<td>0.9901</td>
<td>0.9847</td>
</tr>
<tr>
<td>Logistic Regression</td>
<td>1.63s</td>
<td>1.0000</td>
<td>0.9865</td>
</tr>
<tr>
<td>SVM</td>
<td>0.35s</td>
<td>0.9978</td>
<td>0.9847</td>
</tr>
<tr>
<td>Decision Tree</td>
<td>0.72s</td>
<td>0.9981</td>
<td>0.9390</td>
</tr>
<tr>
<td>Random Forest</td>
<td>3.37s</td>
<td>0.9997</td>
<td>0.9847</td>
</tr>
<tr>
<td>MLP</td>
<td>8.51s</td>
<td>0.9968</td>
<td>0.9883</td>
</tr>
<tr>
<td>bayes-LR Combination Model</td>
<td>1.91s</td>
<td>1.0000</td>
<td>0.9883</td>
</tr>
<tr>
<td>bayes-LR-SVR-RF-MLP Combination Model</td>
<td>12.20s</td>
<td>0.9991</td>
<td>0.9919</td>
</tr>
</tbody>
</table>
</div>
<h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p>Phone number checking was a small attempt made by observing the characteristics of spam emails in the training set, and the effect was quite good.</p>
<p>The accuracy of the Bayesian classifier based on TF-IDF is much higher than that based on bag of words, and the former is also much faster in training speed than the latter.</p>
<p>Among these TF-IDF based models, Bayesian classifiers, logistic regression, support vector machines, random forests, and multi-layer perceptrons all have good accuracy on the training set. Among them, the multi-layer perceptron has the longest training time and the highest accuracy on the test set. The training time for Random Forest is the second longest. The accuracy of logistic regression is slightly better than SVM and Bayesian classifiers, but the training speed is slower compared to them.</p>
<p>Originally, it was expected that the accuracy of the multi-layer perceptron would not be very high because its expressive power was too strong and it was prone to overfitting. However, surprisingly, it was the model with the best accuracy on the test set.</p>
<p>The decision tree exhibits overfitting, which may be related to its strong expressive ability and small dataset size.</p>
<p>The Bayesian logistic regression combination model also has good accuracy on the test set, and the combination model of the five models can achieve the best accuracy, indicating that these individual models do have a tendency to predict spam emails as normal emails on the test set.</p>
<p>Areas that can be improved:</p>
<p>1) Each model is directly adjusted and uses default parameters without parameter tuning. Some models may improve their performance after parameter tuning</p>
<p>2) The text preprocessing is relatively rough and does not recognize and process special strings such as URLs, links, and garbled characters</p>
<p>3) Without multiple training sessions, the ‘Training time’ may not be precise</p>
<p>4) The “combination” between models is relatively simple and crude, and the single model’s “tendency to predict spam into normal mail” has not been explained in principle</p>
<p>5) In terms of interpretability, perhaps one or more collaborative formulas can be used for prediction, which has better interpretability and facilitates monitoring and correction</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/programming-practice/" class="category-chain-item">programming practice</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/machine-learning/" class="print-no-link">#machine learning</a>
      
        <a href="/tags/data-mining/" class="print-no-link">#data mining</a>
      
        <a href="/tags/bayes-classifier/" class="print-no-link">#bayes classifier</a>
      
        <a href="/tags/logistic-regression/" class="print-no-link">#logistic regression</a>
      
        <a href="/tags/SVM/" class="print-no-link">#SVM</a>
      
        <a href="/tags/decision-tree/" class="print-no-link">#decision tree</a>
      
        <a href="/tags/random-forest/" class="print-no-link">#random forest</a>
      
        <a href="/tags/MLP/" class="print-no-link">#MLP</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Spam classification using classic models</div>
      <div>http://example.com/2024/07/26/Spam-classification-using-classic-models/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>Author</div>
          <div>John Doe</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>Posted on</div>
          <div>July 26, 2024</div>
        </div>
      
      
      
        <div class="license-meta-item">
          <div>Licensed under</div>
          <div>
            
              
              
                <a class="print-no-link" target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - Attribution">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/07/27/Install-Ubuntu-Linux-in-VMware/" title="Install Ubuntu Linux in VMware">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">Install Ubuntu Linux in VMware</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/07/24/Add-a-music-player-in-your-Hexo-blog/" title="Add a music player in your Hexo blog">
                        <span class="hidden-mobile">Add a music player in your Hexo blog</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
  
  
    <article id="comments" lazyload>
      
  <div id="valine"></div>
  <script type="text/javascript">
    Fluid.utils.loadComments('#valine', function() {
      Fluid.utils.createScript('https://lib.baomitu.com/valine/1.5.1/Valine.min.js', function() {
        var options = Object.assign(
          {"appId":"88dRqUgSKZbis5Ll3Z2I7ksP-gzGzoHsz","appKey":"5DeS0vBGMOo5VMq9USNgpK5E","path":"window.location.pathname","placeholder":null,"avatar":"retro","meta":["nick","mail","link"],"requiredFields":[],"pageSize":10,"lang":"en","highlight":false,"recordIP":false,"serverURLs":"","emojiCDN":null,"emojiMaps":null,"enableQQ":false},
          {
            el: "#valine",
            path: window.location.pathname
          }
        )
        new Valine(options);
        Fluid.utils.waitElementVisible('#valine .vcontent', () => {
          var imgSelector = '#valine .vcontent img:not(.vemoji)';
          Fluid.plugins.imageCaption(imgSelector);
          Fluid.plugins.fancyBox(imgSelector);
        })
      });
    });
  </script>
  <noscript>Please enable JavaScript to view the comments</noscript>


    </article>
  


          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Hexo</span></a> <i class="iconfont icon-love"></i> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>Fluid</span></a> 
    </div>
  
  
    <div class="statistics">
  
  

  
    
      <span id="leancloud-site-pv-container" style="display: none">
        Visits: 
        <span id="leancloud-site-pv"></span>
        
      </span>
    
    
      <span id="leancloud-site-uv-container" style="display: none">
        Visitors: 
        <span id="leancloud-site-uv"></span>
        
      </span>
    
    

  
</div>

  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script defer src="/js/leancloud.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
</body>
</html>
